{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HyDE 是一种创新方法，它将查询问题转换为包含答案的假设文档，旨在弥合向量空间中查询和文档分布之间的差距。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"MINIMAX_GROUP_ID\"] = os.getenv(\"MINIMAX_GROUP_ID\")\n",
    "os.environ[\"MINIMAX_API_KEY\"] = os.getenv(\"MINIMAX_API_KEY\")\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_community.chat_models import MiniMaxChat\n",
    "from langchain_community.embeddings import MiniMaxEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/二十届三中全会.docx\"\n",
    "loader = Docx2txtLoader(path)\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "chunk_count = len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = MiniMaxEmbeddings()\n",
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    url=\"http://localhost:6333/\",\n",
    "    prefer_grpc=True,\n",
    "    collection_name=\"011\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = MiniMaxChat()\n",
    "\n",
    "hyde_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"chunk_size\"],\n",
    "    template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "    the document size has be exactly {chunk_size} characters.\"\"\",\n",
    ")\n",
    "\n",
    "hyde_chain = hyde_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": 500}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "\n",
    "def retrieve(self, query, k=3):\n",
    "    hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "    similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "    return similar_docs, hypothetical_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
